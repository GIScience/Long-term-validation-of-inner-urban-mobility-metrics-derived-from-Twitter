{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c0aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import notebooks_loops_script as nls\n",
    "import backend_codes.load_subsets as ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604bac0",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "This notebook calculates simple metadata statistics for the respective rolling window. Since the notebook is only for demonstrative porposes, an example is shown here. The parameters of the example rolling windows are defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ca28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"20200406\"\n",
    "end = \"20200409\"\n",
    "denom = \"3days\"\n",
    "allow_even_subsets = False\n",
    "sam = False\n",
    "del_one_tweeters = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9119db5",
   "metadata": {},
   "source": [
    "Six parameters have to be defined for each rolling window.\n",
    "- start: the start date of the rolling window\n",
    "- end: the end date (at 00:00) so tweets on this date are not included\n",
    "- denom: this is for the name of the statistic-file that contains the results\n",
    "- allow_even_subsets: This is relevent for calculating the middle of the respective rolling window\n",
    "- sam: we also explored an approach using a fixed number of tweets for each rolling window of the same size. This can be defined through this parameter.\n",
    "- del_one_tweeters: Since we need at least to tweets of a person in order to infer a movement, tweets of users who only sent one tweet in the respective rolling window are deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b11b3",
   "metadata": {},
   "source": [
    "### Create Reference\n",
    "Create a reference to name the file individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1412b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = \"statistics_notebookdemo/\" + denom + \"_overlap.csv\"\n",
    "if type(sam) == int:\n",
    "    ref = ref.split('.csv')[0] + \"_\" +str(sam) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cef6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"data/{ref}\"\n",
    "nls.check_file(path)\n",
    "file = pd.read_csv(f'data/{ref}', index_col='middle_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43cfebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics_notebookdemo/3days_overlap.csv\n"
     ]
    }
   ],
   "source": [
    "print(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cb6a7",
   "metadata": {},
   "source": [
    "### Load Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c99f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = ls.load_and_subset(start, end, del_one_tweeters=del_one_tweeters, samp_size=sam, tweets_path=\"data/tweets/preprocessed_tweets_with_poi_location.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d0684",
   "metadata": {},
   "source": [
    "# Calculate Metadata and other Basic Statistics\n",
    "Based on the start and enddate, we take a subset of our tweets, calculate metadata and other basic statistics and write them into the respective .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfed956",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9671e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['start_date'] = start\n",
    "stats['end_date'] = end\n",
    "stats[\"no_of_tweets\"] = len(tweets_df)\n",
    "stats[\"number_unique_users\"] = tweets_df.User_ID.nunique()\n",
    "stats[\"median_tweets_per_user\"] = tweets_df.groupby('User_ID').Tweet_ID.count().median()\n",
    "try:\n",
    "    stats[\"mean_tweets_per_user\"] = stats[\"no_of_tweets\"] / stats[\"number_unique_users\"]\n",
    "except:\n",
    "    stats[\"mean_tweets_per_user\"] = np.nan\n",
    "\n",
    "counted = tweets_df.groupby('User_ID').count()\n",
    "stats[\"n_user_more_than_one_tweet\"] = len(counted[counted['Timestamp'] > 1])\n",
    "stats[\"n_users_with_more_than_one_location_point\"] = sum(tweets_df.groupby('User_ID').nunique()['wkt'] > 1)\n",
    "stats[\"n_users_with_more_than_one_cod\"] = sum(tweets_df.groupby('User_ID').nunique()['cod'] > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e6e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = nls.middeling(start, end, allow_even_subsets=allow_even_subsets)\n",
    "middle = int(middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62469e6",
   "metadata": {},
   "source": [
    "### Write into .csv\n",
    "We load the existing .csv with by using our denomination name reference derived from the denomination.\n",
    "Then we overwrite the old data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372609d0",
   "metadata": {},
   "source": [
    "create csv if non existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c2a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, val in stats.items():\n",
    "    file.loc[middle, name] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "059fbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_csv(f'data/{ref}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a450808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date : 20200406\n",
      "end_date : 20200409\n",
      "no_of_tweets : 343\n",
      "number_unique_users : 103\n",
      "median_tweets_per_user : 2.0\n",
      "mean_tweets_per_user : 3.3300970873786406\n",
      "n_user_more_than_one_tweet : 103\n",
      "n_users_with_more_than_one_location_point : 42\n",
      "n_users_with_more_than_one_cod : 30\n"
     ]
    }
   ],
   "source": [
    "for key, val in stats.items():\n",
    "    print(key, \":\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a590e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
